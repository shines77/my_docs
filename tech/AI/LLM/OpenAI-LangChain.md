# OpenAI LangChain

## 1. ç®€ä»‹

LangChain æ˜¯ä¸€ä¸ªç”¨äºŽå¼€å‘ç”±å¤§åž‹è¯­è¨€æ¨¡åž‹ï¼ˆLLMsï¼‰é©±åŠ¨çš„åº”ç”¨ç¨‹åºçš„æ¡†æž¶ã€‚

LangChain ç®€åŒ–äº† LLM åº”ç”¨ç¨‹åºç”Ÿå‘½å‘¨æœŸçš„æ¯ä¸ªé˜¶æ®µï¼š

- **å¼€å‘**ï¼šä½¿ç”¨ LangChain çš„å¼€æºæž„å»ºå—ã€ç»„ä»¶å’Œç¬¬ä¸‰æ–¹é›†æˆæ¥æž„å»ºæ‚¨çš„åº”ç”¨ç¨‹åºã€‚ä½¿ç”¨ LangGraph æž„å»ºå…·æœ‰ä¸€æµçš„æµå¼ä¼ è¾“å’Œäººå·¥å‚ä¸Žæ”¯æŒçš„æœ‰çŠ¶æ€ä»£ç†ã€‚
- **ç”Ÿäº§åŒ–**ï¼šä½¿ç”¨ LangSmith æ£€æŸ¥ã€ç›‘æŽ§å’Œè¯„ä¼°æ‚¨çš„ Chainï¼Œä»¥ä¾¿æ‚¨å¯ä»¥æ”¾å¿ƒåœ°æŒç»­ä¼˜åŒ–å’Œéƒ¨ç½²ã€‚
- **éƒ¨ç½²**ï¼šä½¿ç”¨ LangGraph Cloud å°†æ‚¨çš„ LangGraph åº”ç”¨ç¨‹åºè½¬æ¢ä¸ºç”Ÿäº§å°±ç»ªçš„ API å’ŒåŠ©æ‰‹ã€‚

![langchain stack](./images/langchain_stack_062024.svg)

å…·ä½“æ¥è¯´ï¼Œè¯¥æ¡†æž¶ç”±ä»¥ä¸‹å¼€æºåº“ç»„æˆï¼š

- `**langchain-core**`ï¼šåŸºç¡€æŠ½è±¡å’Œ LangChain è¡¨è¾¾å¼è¯­è¨€ã€‚
- `**langchain-community**`ï¼šç¬¬ä¸‰æ–¹é›†æˆã€‚
  - åˆä½œä¼™ä¼´åŒ…ï¼ˆä¾‹å¦‚ `**langchain-openai**`ã€`**langchain-anthropic**` ç­‰ï¼‰ï¼šä¸€äº›é›†æˆå·²è¢«è¿›ä¸€æ­¥æ‹†åˆ†ä¸ºä»…ä¾èµ–äºŽ `**langchain-core**`çš„è½»é‡çº§åŒ…ã€‚
- `**langchain**`ï¼šæž„æˆåº”ç”¨ç¨‹åºè®¤çŸ¥æž¶æž„çš„ Chainã€Agent å’Œæ£€ç´¢ç­–ç•¥ã€‚
- **LangGraph**ï¼šé€šè¿‡å°†æ­¥éª¤å»ºæ¨¡ä¸ºå›¾ä¸­çš„è¾¹å’ŒèŠ‚ç‚¹ï¼Œä½¿ç”¨ LLM æž„å»ºå¥å£®ä¸”æœ‰çŠ¶æ€çš„å¤šå‚ä¸Žè€…åº”ç”¨ç¨‹åºã€‚ä¸Ž LangChain å¹³æ»‘é›†æˆï¼Œä½†ä¹Ÿå¯ä»¥ä¸ä½¿ç”¨å®ƒã€‚
- **LangServe**ï¼šå°† LangChain é“¾éƒ¨ç½²ä¸º REST APIã€‚
- **LangSmith**ï¼šä¸€ä¸ªå¼€å‘è€…å¹³å°ï¼Œè®©æ‚¨å¯ä»¥è°ƒè¯•ã€æµ‹è¯•ã€è¯„ä¼°å’Œç›‘æŽ§ LLM åº”ç”¨ç¨‹åºã€‚

æ³¨æ„

æœ¬æ–‡æ¡£ä¾§é‡äºŽ Python LangChain åº“ã€‚å‰å¾€è¿™é‡ŒæŸ¥çœ‹ [JavaScript LangChain](https://js.langchain.com/) åº“çš„æ–‡æ¡£ã€‚

### æ•™ç¨‹

å¦‚æžœæ‚¨æƒ³è¦æž„å»ºç‰¹å®šçš„ä¸œè¥¿æˆ–è€…æ›´å–œæ¬¢åŠ¨æ‰‹å­¦ä¹ ï¼Œè¯·æŸ¥çœ‹æˆ‘ä»¬çš„æ•™ç¨‹éƒ¨åˆ†ã€‚

è¿™äº›æ˜¯æœ€ä½³çš„å…¥é—¨æ•™ç¨‹ï¼š

- [æž„å»ºä¸€ä¸ªç®€å•çš„ LLM åº”ç”¨ç¨‹åº](https://python.langchain.com/docs/tutorials/llm_chain/)
- [æž„å»ºä¸€ä¸ªèŠå¤©æœºå™¨äºº (ChatBot)](https://python.langchain.com/docs/tutorials/chatbot/)
- [æž„å»ºä¸€ä¸ª AI ä»£ç† (AI Agent)](https://python.langchain.com/docs/tutorials/agents/)
- [LangGraph çš„ç®€ä»‹](https://langchain-ai.github.io/langgraph/tutorials/introduction/)

åœ¨è¿™é‡ŒæŸ¥çœ‹ LangChain å®Œæ•´æ•™ç¨‹åˆ—è¡¨ï¼Œå¹¶æŸ¥çœ‹å…¶ä»– [LangGraph æ•™ç¨‹](https://langchain-ai.github.io/langgraph/tutorials/)ã€‚è¦äº†è§£æ›´å¤šå…³äºŽ LangGraph çš„ä¿¡æ¯ï¼Œè¯·æŸ¥çœ‹æˆ‘ä»¬ç¬¬ä¸€ä¸ª LangChain çš„å­¦é™¢è¯¾ç¨‹ï¼šã€ŠLangGraph çš„ç®€ä»‹ã€‹ï¼Œå¯ä»¥åœ¨[è¿™é‡Œ](https://academy.langchain.com/courses/intro-to-langgraph)æ‰¾åˆ°ã€‚

### æ“ä½œæŒ‡å—

åœ¨è¿™é‡Œï¼Œæ‚¨ä¼šæ‰¾åˆ°â€œæˆ‘è¯¥å¦‚ä½•â€¦â€¦ï¼Ÿâ€è¿™ç±»é—®é¢˜çš„ç®€çŸ­ç­”æ¡ˆã€‚è¿™äº›æ“ä½œæŒ‡å—ä¸ä¼šæ·±å…¥è¦†ç›–ä¸»é¢˜â€”â€”æ‚¨ä¼šåœ¨æ•™ç¨‹å’Œ API å‚è€ƒä¸­æ‰¾åˆ°ææ–™ã€‚ç„¶è€Œï¼Œè¿™äº›æŒ‡å—å°†å¸®åŠ©æ‚¨å¿«é€Ÿå®Œæˆå¸¸è§ä»»åŠ¡ã€‚

åœ¨è¿™é‡ŒæŸ¥çœ‹ [LangGraph ç‰¹å®šçš„æ“ä½œæŒ‡å—](https://langchain-ai.github.io/langgraph/how-tos/)ã€‚

### æ¦‚å¿µæŒ‡å—

æ‚¨éœ€è¦äº†è§£çš„ LangChain æ‰€æœ‰å…³é”®éƒ¨åˆ†çš„ä»‹ç»ï¼åœ¨è¿™é‡Œï¼Œæ‚¨å°†æ‰¾åˆ°æ‰€æœ‰ LangChain æ¦‚å¿µçš„é«˜çº§è§£é‡Šã€‚

è¦æ·±å…¥äº†è§£ LangGraph æ¦‚å¿µï¼Œè¯·æŸ¥çœ‹æ­¤é¡µé¢ã€‚

### API å‚è€ƒ

å‰å¾€å‚è€ƒéƒ¨åˆ†èŽ·å– LangChain Python åŒ…ä¸­æ‰€æœ‰ç±»å’Œæ–¹æ³•çš„å®Œæ•´æ–‡æ¡£ã€‚

### ç”Ÿæ€ç³»ç»Ÿ

#### ðŸ¦œðŸ› ï¸ LangSmith

è¿½è¸ªå’Œè¯„ä¼°æ‚¨çš„è¯­è¨€æ¨¡åž‹åº”ç”¨ç¨‹åºå’Œæ™ºèƒ½ä»£ç†ï¼Œå¸®åŠ©æ‚¨ä»ŽåŽŸåž‹è¿‡æ¸¡åˆ°ç”Ÿäº§ã€‚

[LangSmith æ–‡æ¡£](https://docs.smith.langchain.com/)

#### ðŸ¦œðŸ•¸ï¸ LangGraph

ä½¿ç”¨ LLMs æž„å»ºæœ‰çŠ¶æ€çš„å¤šå‚ä¸Žè€…åº”ç”¨ç¨‹åºã€‚ä¸Ž LangChain å¹³æ»‘é›†æˆï¼Œä½†ä¹Ÿå¯ä»¥ä¸ä½¿ç”¨å®ƒã€‚

[LangGraph æ–‡æ¡£](https://langchain-ai.github.io/langgraph/)

### Log your first trace

python ç‰ˆæœ¬ï¼š

```python
import openai
from langsmith.wrappers import wrap_openai
from langsmith import traceable

# Auto-trace LLM calls in-context
client = wrap_openai(openai.Client())

@traceable # Auto-trace this function
def pipeline(user_input: str):
    result = client.chat.completions.create(
        messages=[{"role": "user", "content": user_input}],
        model="gpt-3.5-turbo"
    )
    return result.choices[0].message.content

pipeline("Hello, world!")
# Out:  Hello there! How can I assist you today?
```

### Run your first evaluation

python ç‰ˆæœ¬ï¼š

```python
from langsmith import Client, evaluate
client = Client()

# Define dataset: these are your test cases
dataset_name = "Sample Dataset"
dataset = client.create_dataset(dataset_name, description="A sample dataset in LangSmith.")
client.create_examples(
  inputs=[
      {"postfix": "to LangSmith"},
      {"postfix": "to Evaluations in LangSmith"},
  ],
  outputs=[
      {"output": "Welcome to LangSmith"},
      {"output": "Welcome to Evaluations in LangSmith"},
  ],
  dataset_id=dataset.id,
)

# Define your evaluator
def exact_match(run, example):
  return {"score": run.outputs["output"] == example.outputs["output"]}

experiment_results = evaluate(
  lambda input: "Welcome " + input['postfix'], # Your AI system goes here
  data=dataset_name, # The data to predict and grade over
  evaluators=[exact_match], # The evaluators to score the results
  experiment_prefix="sample-experiment", # The name of the experiment
  metadata={
    "version": "1.0.0",
    "revision_id": "beta"
  },
)
```

## 2. LangSmith

### æ¦‚å¿µ

è¿™ç¯‡æ¦‚å¿µæŒ‡å—æ¶µç›–äº†åœ¨å°†è¿½è¸ªè®°å½•åˆ° LangSmith æ—¶æ‚¨éœ€è¦äº†è§£çš„ä¸»é¢˜ã€‚è·Ÿè¸ªæœ¬è´¨ä¸Šæ˜¯åº”ç”¨ç¨‹åºä»Žè¾“å…¥åˆ°è¾“å‡ºçš„ä¸€ç³»åˆ—æ­¥éª¤ã€‚æ¯ä¸ªå•ç‹¬çš„æ­¥éª¤éƒ½ç”±ä¸€ä¸ª Run è¡¨ç¤ºã€‚ä¸€ä¸ªé¡¹ç›®ä»…ä»…æ˜¯ä¸€ç»„è¿½è¸ªè®°å½•ã€‚ä¸‹å›¾åœ¨ç®€å• RAG åº”ç”¨ç¨‹åºçš„ä¸Šä¸‹æ–‡ä¸­å±•ç¤ºäº†è¿™äº›æ¦‚å¿µï¼Œè¯¥åº”ç”¨ç¨‹åºä»Žç´¢å¼•ä¸­æ£€ç´¢æ–‡æ¡£å¹¶ç”Ÿæˆç­”æ¡ˆã€‚

![LangSmith æ¦‚å¿µå›¾](./images/OpenAI-LangSmith-Concepts.png)

### Runs

ä¸€ä¸ª Run æ˜¯ä¸€ä¸ªæ—¶é—´æ®µï¼Œä»£è¡¨æ‚¨çš„ LLM åº”ç”¨ç¨‹åºä¸­å•ä¸ªå·¥ä½œå•ä½æˆ–æ“ä½œã€‚è¿™å¯ä»¥æ˜¯ä»Žå¯¹ LLM æˆ– Chain çš„å•ä¸ªè°ƒç”¨ï¼Œåˆ°æç¤ºæ ¼å¼åŒ–è°ƒç”¨ï¼Œå†åˆ°å¯è¿è¡Œçš„ lambda è°ƒç”¨ã€‚å¦‚æžœä½ ç†Ÿæ‚‰ [OpenTelemetry](https://opentelemetry.io/)ï¼Œä½ å¯ä»¥æŠŠ Run çœ‹ä½œä¸€ä¸ª Span ã€‚

è¦äº†è§£æœ‰å…³ Run å¦‚ä½•åœ¨åº”ç”¨ç¨‹åºä¸­å­˜å‚¨çš„æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚é˜…æœ¬ [å‚è€ƒæŒ‡å—](https://docs.smith.langchain.com/reference/data_formats/run_data_format) ã€‚

### Traces

ä¸€ä¸ª Trace æ˜¯ä¸€ç³»åˆ—ç›¸å…³çš„ Runï¼Œå®ƒä»¬ä¸Žå•ä¸ªæ“ä½œæœ‰å…³ã€‚ä¾‹å¦‚ï¼Œå¦‚æžœæ‚¨æœ‰ä¸€ä¸ªç”¨æˆ·è¯·æ±‚è§¦å‘äº†é“¾ï¼Œè€Œè¿™ä¸ªé“¾åˆè°ƒç”¨äº† LLMï¼Œç„¶åŽè°ƒç”¨äº†è¾“å‡ºè§£æžå™¨ï¼Œç­‰ç­‰ï¼Œæ‰€æœ‰è¿™äº›è¿è¡Œéƒ½å°†å±žäºŽåŒä¸€ä¸ª Trace ã€‚å¦‚æžœæ‚¨ç†Ÿæ‚‰ [OpenTelemetry](https://opentelemetry.io/)ï¼Œæ‚¨å¯ä»¥è®¤ä¸º LangSmith çš„ Trace æ˜¯ä¸€ç³»åˆ— span çš„é›†åˆï¼ŒRuns é€šè¿‡å”¯ä¸€çš„ Trace ID ç»‘å®šåˆ° Trace ä¸Šã€‚

### Projects

Project æ˜¯ Trace çš„é›†åˆã€‚æ‚¨å¯ä»¥å°† Project è§†ä¸ºä¸Žå•ä¸ªåº”ç”¨ç¨‹åºæˆ–æœåŠ¡ç›¸å…³çš„æ‰€æœ‰ Trace çš„å®¹å™¨ã€‚æ‚¨å¯ä»¥æœ‰å¤šä¸ª Projectï¼Œæ¯ä¸ª Project éƒ½å¯ä»¥æœ‰å¤šæ¡ Trace ã€‚

### èŒƒä¾‹

python ç‰ˆæœ¬ï¼š

```python
from langsmith import evaluate, Client
from langsmith.schemas import Example, Run

# 1. Create and/or select your dataset
client = Client()
dataset = client.clone_public_dataset("https://smith.langchain.com/public/a63525f9-bdf2-4512-83e3-077dc9417f96/d")

# 2. Define an evaluator
# For more info on defining evaluators, see: https://docs.smith.langchain.com/evaluation/how_to_guides/evaluation/evaluate_llm_application#use-custom-evaluators
def is_concise_enough(root_run: Run, example: Example) -> dict:
  score = len(root_run.outputs["output"]) < 3 * len(example.outputs["answer"])
  return {"key": "is_concise", "score": int(score)}

# 3. Run an evaluation
evaluate(
  lambda x: x + "is a good question. I don't know the answer.",
  data=dataset.name,
  evaluators=[is_concise_enough],
  experiment_prefix="my first experiment "
)
```

## 3. å‚è€ƒæ–‡ç« 

- [LangChain Introduction](https://python.langchain.com/docs/introduction/)

- [Get started with LangSmith](https://docs.smith.langchain.com/)

- [LangChain: LangSmith Concepts](https://docs.smith.langchain.com/observability/concepts)

- [LangChain: LangGraph](https://langchain-ai.github.io/langgraph/)

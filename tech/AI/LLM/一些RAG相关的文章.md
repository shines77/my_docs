# 一些 RAG 相关的文章

## 1. 一些思考

- [RAG的上限在哪里？边界在哪里？](https://blog.csdn.net/star1210644725/article/details/140088334) | 推荐指数：★★★★

    本篇文章探讨的问题，主要是在知识库文档问答方向的 RAG。

    RAG 的链路大概是：文档解析 -> 文档分割（chunch）-> 文档存储（BM25 和向量存储）-> 检索召回-> 模型回答。 这是一条比较简单的路线。

    稍微复杂一点的链路是：文档解析-> 文档分割（chunch） -> 文档存储（BM25 和向量存储）-> 检索召回 -> 粗排 -> 精排 -> 重排 -> prompt工程（PE）-> 模型回答。这条路线，在召回层面做了优化。能够一定程度上提升 RAG 的效果。

    再复杂一点的链路是：文档解析-> 文档分割（chunch） -> 文档存储（BM25 和向量存储）-> query理解 -> 意图识别 -> query rewrite -> 检索召回 -> 粗排 -> 精排 -> 重排 -> prompt工程（PE）-> 模型回答。加了 意图 和 query 理解后，一方面会变得更加智能，另外一方面会提升召回的效果，这都会提升 RAG 的效果。

    排序的边界问题：这里的排序，包括粗排，精排，重排。这个过程的目标是把真正的答案放在前边。

来自 Kimi Chat 的总结：

这篇文章探讨了 RAG（Retrieval Augmented Generation）技术的上限和边界，特别是在知识库文档问答方向的应用。

以下是文章的主要内容总结：

1. **RAG的多个方向**：

   - 文章主要关注基于知识库文档问答方向的 RAG。

2. **RAG的链路**：

   - 简单的 RAG 链路包括：文档解析、文档分割、文档存储、检索召回和模型回答。
   - 复杂一些的链路增加了粗排、精排和重排。
   - 更复杂的链路进一步加入了 query 理解、意图识别、query 改写等步骤。

3. **RAG的边界问题**：

   - RAG 在实际应用中可能会遇到无力感，因为客户期望 RAG 的能力远超模型的实际能力。
   - 文档切分的边界问题：RAG 更擅长回答文档中已有的问题，且问题最好只出现在切分后的某个片段中。
   - 召回方式的边界问题：最常见的召回方式是 BM25 召回和基于向量的语义召回，这两种方式的能力上限取决于做 embedding 的模型的能力。
   - 排序的边界问题：排序包括粗排、精排和重排，目标是将真正的答案排在前面，但排序并不总是好的，可能会丢失重要内容。

4. **RAG所需的技术**：

   - 知识工程：整理文档、解析文档、知识梳理和挖掘的能力。
   - 存储引擎、检索和召回：需要会使用如 Elasticsearch 这样的搜索引擎。
   - NLP 和算法基础：包括意图识别、query 理解、query 改写、粗排、精排等。

5. **有意思的探索**：

   - HyDE（Hypothetical Document Embeddings）：通过模型生成假设性答案，然后检索相关文档。
   - Query 拆解 CoT（Chain of Thought）：对复杂 query 进行逐步拆解以回答。
   - 预先生成 QA：提前生成 QA 以解决特殊 query 。
   - 意图识别：判断问题是否应该由模型直接回答还是通过知识库检索。
   - 知识图谱：解决复杂关联知识对应的问题，弥补传统 RAG 的缺陷。

文章强调了 RAG 是一个综合性的方向，需要多种技术的支持，并且指出了 RAG 在实际应用中的一些限制和挑战。作者通过分享自己的经验和见解，为读者提供了对 RAG 技术上限和边界的深入理解。

- [大模型未来发展：RAG vs 长文本，谁更胜一筹？｜Z 沙龙第 8 期](https://blog.csdn.net/fogdragon/article/details/137031269) | 推荐指数：★★★★

    ```text
    RAG vs 长文本，谁更胜一筹？

    1、观点一：RAG 与长文本各有所长
    2、观点二：长文本将取代 RAG
    3、观点三：RAG 和长文本分工已经明确，不存在争议空间
    4、观点四：长文本和 RAG 需要结合
    5、观点五：RAG 是大模型发展的中间态，短期内长文本无法替代 RAG
    ```

## 2. RAG 原理

- [万字长文！RAG的实战指南及探索之路](https://blog.csdn.net/Z4400840/article/details/144430497) | 推荐指数：★★★★

这篇文章是关于 RAG（Retrieval Augmented Generation，检索增强生成）的实战指南和探索之路的详细介绍。

该方法是 Meta 在 2020 年发表的文章《Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks》中提出的。

以下是文章的主要内容总结：

**背景介绍：**

- RAG 结合了基于检索的模型和生成模型的能力，以提高生成文本的质量和相关性。
- RAG 由 Meta 在 2020年 提出，旨在让语言模型（LM）能够获取内化知识之外的信息，并在专业知识库的基础上更准确地回答问题。
- RAG 在大模型时代用于解决幻觉问题、知识时效问题、超长文本问题等。

**RAG的挑战：**

- 检索质量：包括语义歧义、用户输入变复杂、文档切分、多模内容的提取及表征等问题。
- 增强过程：涉及上下文的集成、冗余和重复、排名和优先级等挑战。
- 生成质量：包括过度依赖检索内容、无关性、毒性或偏见等问题。

**整体架构：**

- 产品架构包含模型层、离线理解层、在线问答层和场景层。
- 技术架构分为 query 理解、检索模型和生成模型三个主要部分。

**Query理解：**

- 包括意图识别、query 改写、query 扩写、query 重构等模块，旨在提高检索的相关性和准确性。

**检索模型：**

- 检索模型的挑战，面临依赖于 Embedding 模型的向量化准确性、外部数据的合理分割、Prompt 拼接等挑战。
- 包括文档加载器、文本转换器、文本嵌入模型、向量数据库和索引等组件，以及 "排序" 和 "后处理" 。

**生成模型：**

- 基于检索出的相关信息生成回复，涉及回复生成策略和 prompt 拼接策略。

**插件（Demonstration Retriever for In-Context Learning）：**

- 基于演示检索的上下文学习方法，通过检索与测试输入相似的候选示范性示例，提高模型预测的准确性。
- 具体的架构：包括检索模块、重排模块和生成模块。

**引用或归因（attribution）生成：**

- 在知识问答场景下，归因可以提供证据来源，确保信息准确性，使大模型的回答更加真实。

**评估：**

- 讨论了如何量化业务指标，以及评估 RAG 系统性能的几个方面，包括位置偏见和检索内容相关性。
- 提到了评测指标，如 Faithfulness、Answer Relevance、Context Relevance，以及评测方法，如 RGB 和 RAGAS 。
- RGB（Benchmarking Large Language Models in Retrieval-Augmented Generation）。
- RAGAS（Automated Evaluation of Retrieval Augmented Generation）。[GitHub](https://github.com/explodinggradients/ragas)
- Llamalindex-Evaluating：提供了衡量生成结果质量的关键模块。同时，还提供关键模块来衡量检索质量。


## 3. RAG 开源模型



## 4. RAG 应用




## 5. 其他



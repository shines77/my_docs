# 关于 C 和 C++ 哈希表的广泛基准测试

## 原文

原标题：[An Extensive Benchmark of C and C++ Hash Tables](https://jacksonallan.github.io/c_cpp_hash_tables_benchmark/)

链接：[https://jacksonallan.github.io/c_cpp_hash_tables_benchmark/](https://jacksonallan.github.io/c_cpp_hash_tables_benchmark/)

## 引言：为什么还要进行另一个哈希表基准测试？

尽管近年来其他人已经发布了全面的哈希表基准测试，但由于几个原因，我决定贡献另一个基准测试套件。首先，现有的基准测试主要集中在 C++ 哈希表上，而对 C 哈希表的覆盖相对较少。因此，C 程序员往往被引导使用较旧的、众所周知的库，尽管可能存在性能更优越的新库。其次，现有基准测试报告的结果大多是累积的，因此它们不能清楚地显示在特定条件下的表现，如表在特定的负载因子下，被测试表的性能。此外，一些现有的基准测试只测试一个键类型或存储桶大小，这使得很难对给定表的性能得出一般性的结论。最后的动机是个人兴趣：我最近发布了一个新颖的 C 语言通用哈希表（通过 Verstable 和 CC），我想展示它与领先的 C++ 哈希表以及其他 C 语言领域中可用的表相比如何。

## 基准测试设置

基准测试包括三种哈希表配置，旨在在不同条件下测量表的性能：

- **32位整数键，32位值**：基准测试检查当键哈希和比较函数便宜时，表的性能如何，遍历桶便宜（即不会引起许多缓存未命中），并且移动键值对便宜。这些基准测试不利于在单独数组中存储元数据的表，因为这样做必然会导致每次查找至少多一次缓存未命中。

- **64位整数键，448位值**：基准测试检查当哈希和比较函数便宜时，表的性能如何，遍历桶昂贵（在64字节缓存行的架构上，每个桶一个缓存未命中），并且移动键值对昂贵。这些基准测试不利于不将元数据存储在单独数组中的表（或者这样做，但每次探针无论如何都要访问桶数组以检查键）以及经常移动键值对的表（例如，Robin Hood 哈希表）。

- **16字符C字符串键，64位值**：基准测试检查当哈希和比较函数昂贵时，表的性能如何。表存储的键是指向连续分配的字符串数组中的指针。这些基准测试不利于缺乏限制键比较的元数据机制或经常重新哈希键的表。

所有基准测试的表都配置为使用相同的哈希函数，即整数键的 MurmurHash3finalizer 和字符串键的 FNV-1a 。

所有表的最大负载因子设置为 0.875。因此，由于所有表（GCC下的 std::unordered_map 除外）一旦达到最大负载因子就通过加倍桶数来增长，结果显示了每个表在大约 0.44（图表中的低谷）到 0.875（图表的高峰）的负载因子范围内的性能。我选择这个限制是因为它相对较高，几个有硬编码的、不可定制的最大负载因子的表（即 absl::flat_hash_map 和 boost::unordered_flat_map ）使用它。

整数键数据集由随机洗牌的连续整数组成，字符串密钥数据集由随机混洗的以 NULL 结尾的连续字符串组成。

代码是使用 GCC 13.2.0 通过 MinGW-w64 编译的，使用 `-O3` 和 `-DNDEBUG` 。基准测试在频率锁定在 90% 的 AMD Ryzen 7 5800H 上运行。

至于基准测试本身，它们包括以下内容：

- **向表中插入N个不存在的键所需的总时间**：在这个基准测试中，N个唯一键被插入到表中。在此过程中的偶数间隔，记录从基准测试开始以来经过的总时间。因此，这个基准测试的结果与其他所有基准测试不同，是累积的。

- **在表中有N个键时，删除1,000个现有键所需的时间**：在这个基准测试中，N 个唯一键被插入到表中。在此过程中的偶数间隔，删除 1,000 个键，并记录完成此操作所需的时间。这些键包括在已插入的键序列中随机选择的 1,000 个键序列。键被删除后，它们被重新插入到表中，然后继续插入唯一键的过程。

- **在表中有N个键时，替换1,000个现有键所需的时间**：在这个基准测试中，N个唯一键被插入到表中。在此过程中的偶数间隔，重新插入 1,000 键，并记录完成此操作所需的时间。这些键包括在已插入的键序列中随机选择的 1,000 个键序列。

- **在表中有N个键时，删除1,000个不存在的键所需的时间**：在这个基准测试中，N 个唯一键被插入到表中。在此过程中的偶数间隔，调用删除函数删除 1,000 个未插入的键，并记录完成此操作所需的时间。这些键包括在从未插入的键的单独序列中随机选择的 1,000 个键序列。

- **在表中有N个键时，查找1,000个现有键所需的时间**：在这个基准测试中，N 个唯一键被插入到表中。在此过程中的偶数间隔，查找1,000个键，并记录完成此操作所需的时间。这些键包括在已插入的键序列中随机选择的 1,000 个键序列。

- **在表中有N个键时，查找1,000个不存在的键所需的时间**：在这个基准测试中，N 个唯一键被插入到表中。在此过程中的偶数间隔，调用查找函数查找1,000个未插入的键，并记录完成此操作所需的时间。这些键包括在从未插入的键的单独序列中随机选择的 1,000 个键序列。

- **在表中有N个键时，遍历5,000个键所需的时间**：在这个基准测试中，N 个唯一键被插入到表中。在此过程中的偶数间隔，遍历表中的5,000个键，并记录完成此操作所需的时间。迭代开始的位置是通过查找已插入键序列中的随机键找到的。

上述基准测试中，《在表中有 N 个键时，替换 1,000 个现有键所需的时间》、《在表中有N个键时，删除 1,000 个不存在的键所需的时间》、《在表中有 N 个键时，查找 1,000 个现有键所需的时间》、《在表中有N个键时，查找 1,000 个不存在的键所需的时间》和《在表中有 N 个键时，遍历 5,000 个键所需的时间》是作为插入 N 个唯一键的同一过程的一部分并行执行的。

这个基准测试设置有一些局限性。首先，测试的负载因子范围如前所述大约是 0.44 到 0.875 。因此，结果不显示在较低负载因子下的性能。由于一些表的默认最大负载因子低至 0.5，它们主要在超出其作者预期的负载因子范围内进行测量。其次，基准测试不测量内存使用情况。然而，至少每个开放寻址表的内存使用情况可以根据它能够合理容忍的最大负载因子和每个桶的内存开销来估计。第三，尽管选择 MurmurHash3finalizer 作为整数哈希函数确保了所有表在平等的基础上竞争，没有一个因弱哈希函数而受损，但它可能不利于能够容忍快速但弱哈希函数的表（例如，默认的整数哈希函数 std::unordered_map 通常是恒等函数，而 ankerl::unordered_dense、absl::flat_hash_map、boost::unordered_flat_map、CC 的 cc_map 和 Verstable 都需要或受益于提供哈希码所有位上的熵的哈希函数）。最后，基准测试很少显示墓碑对依赖它们的表的性能的累积影响，当擦除频繁时。

基准测试的完整代码可在 [此处](https://github.com/JacksonAllan/c_cpp_hash_tables_benchmark) 获得。

## 基准测试的哈希表

### C++ 哈希表

- absl::flat_hash_map v20240116.2：

由 Google 开发，这个表在 Abseil 网站上以及通过两次演讲得到了充分的记录。它是一个开放寻址表，存储每个键的哈希码的 7 位片段在单独的数组中，并使用 SIMD 指令一次扫描 16 个桶的潜在键匹配。它依赖墓碑进行擦除。

这个表的近似内存开销是每个桶一个字节，加上键值对填充，除了空桶的键值对大小。

- ankerl::unordered_dense v4.1.2：

这个表采用 Robin Hood 排序——这是一种开放寻址变体，它移动键值对以保持它们从哈希到的桶的位移尽可能恒定——结合线性探测。然而，它对 Robin Hood 设计做了两个补充。首先，它不是在表的桶内存储键值对，而是在单独的数组中连续存储。表桶存储此数组的索引。其次，它存储每个键的哈希码的8位片段，以限制直接比较键的需要。这个表是同一作者早期表的后继者，我之所以没有在本文中包括早期的表，是因为它已被弃用，并且在我早期的测试中被证明较差。

默认情况下，这个表只能容纳 2^32（42.9亿）键值对。支持更高数量可以在额外内存使用和较少缓存友好性的代价下启用。对于这些基准测试，我使用了默认限制。

在 x86-64 上，这个表的近似内存开销是每个桶八个字节（或者对于可以容纳超过 2^32 键值对的表是 12 个字节），加上键值对填充，除了空桶的键值对大小。

- boost::unordered_flat_map v1.85.0：

这个表也是一个开放寻址表，存储哈希码片段在单独的数组中，并使用SIMD指令一次扫描多个桶的潜在键匹配。然而，它与 absl::flat_hash_map 有几个重要的不同。首先，键不是哈希到单个桶，而是哈希到 15 个桶组，这些组从一个端到另一个端连续填充：

其次，哈希码片段由 7.99 位而不是 7 位组成。第三，表不使用墓碑，而是使用其作者称之为“overflow byte”的组级布隆过滤器，这也加速了查找不存在的键（下面，我将这种机制视为“tombstone-like (类墓碑的)”，因为擦除仍然会对表的性能留下残留影响，并导致更频繁的全表重新哈希）。上述细节等更多内容通过演讲记录。

这个表的近似内存开销是每个桶 1.07 个字节，加上键值对填充，除了空桶的键值对大小。

为了方便与这个基准测试项目一起分发，我选择了使用第三方提供的这个表的 [合并单头版本 (amalgamated single-header version)](https://github.com/MikePopoloski/boost_unordered)。然而，Boost.Unordered，包含这个表的 Boost 模块，也可以从官方源直接单独获得和安装。

- emilib2::HashMap：

这个表是另一个使用 SIMD 指令一次扫描多个哈希码片段以寻找潜在键匹配的开放寻址表。该库仍在开发中，关于其实现的细节稀少且可能变化。其近似内存开销是每个桶 1.25 个字节，加上键值对填充，除了空桶的键值对大小。

基准测试的版本是emilib2o.hpp 434a205，我修改了它以将最大负载因子设置为 0.875。

- ska::bytell_hash_map：

这个表是其作者对各种哈希表设计的实验成果，包括 Robin Hood 和 SIMD 加速表。它通过他交付的演讲得到了最充分的记录。该表是开放寻址和分离链表的混合体。从一个桶溢出的键值对存储在同一数组的其他空桶中，并使用 7 位“跳转距离”（索引到硬编码的可能距离数组，以桶为单位，到链中的下一个键值对）链式连接。这种元数据组——即 7 位跳转距离与1位标志——与桶组交错存储（每 16 个字节的元数据后面跟着 16 个相应的桶）。这种设计与称为合并哈希的旧技术相似，只是链不合并。

这个表的近似内存开销是每个桶一个字节，加上键值对填充，除了空桶的键值对大小。

不幸的是，该库似乎无人维护。

- std::unordered_map from GCC 13.2.0：

这是许多开发者的首选哈希表，因为它是C++标准库的一部分。虽然实现可能在细节上有所不同，但C++标准施加的约束实际上规定了这个表使用基于节点的分离链表，而不是开放寻址。

在 x86-64 上，这个表的近似内存开销是每个桶八个字节，以及每个键值对八个字节，加上指针键值对填充和 malloc 头和填充。然而，由于许多小分配引起的可用内存碎片化，其实际内存影响可能更大。

- tsl::robin_map v1.3.0：

这是另一个流行的 Robin Hood 表。与 ankerl::unordered_dense 不同，它在桶数组内存储键值对、它们从理想桶的位移，以及（在某些条件下）哈希码。因此，它是一个更传统的 Robin Hood 设计的实现。

在 x86-64 上，这个表的近似内存开销是每个桶三个字节，加上 uint16_t-bool-键值对 填充，除了空桶的键值对大小。

### C 哈希表

- cc_map from CC v1.1.1：

这个表在 CC 的 API 约束内实现 Verstable。详见下文。

- khash from klib v0.2.8：

这是一个非常流行的开放寻址表，默认使用二次探测。它将键和值存储在两个单独的数组中（除了第三个元数据数组），而不是交错在一个桶数组中。这种选择通过消除填充字节节省了内存，但这意味着查找现有键必然涉及额外的缓存未命中。该表依赖墓碑进行擦除。

这个表的近似内存开销是每个桶 0.25 个字节，除了空桶的键和值的大小。

请注意，klib 还包括一个较新的哈希表，称为 khashl，使用线性探测而没有墓碑。这个表没有包括在这些基准测试中。

- DICT from M*LIB v0.7.3：

这是另一个默认使用二次探测的开放寻址表。像 ankerl::unordered_dense 和 stb_ds 的 hm 和 sh（下面描述）一样，它在数组中单独存储键值对，而不是在桶数组中。桶数组存储索引到键值对数组，以及哈希码。与其他两个表不同，擦除时它不将数组中的最后一个键值对向后移动以填补创建的空白（这个过程需要另一个查找以更新存储在桶数组中的移动对的索引）。擦除依赖墓碑。

这个表也只能容纳 2^32 键值对，默认情况下，启用支持更高数量会影响内存使用和缓存效率。对于这些基准测试，我使用了默认限制。

这个表的近似内存开销是每个桶八个字节（或者对于可以容纳超过 2^32 键值对的表是 16 个字节），加上键值对填充，除了空桶的键值对大小。

- DICT_OA from M*LIB v0.7.3：

像 DICT 一样，DICT_OA 是一个默认使用二次探测的开放寻址表。然而，它更传统，因为它在表桶内存储键和值。它的突出特点是，它不存储每个桶的元数据，而是要求用户预留两个键以标记空桶和墓碑。因此，该表通常可以更密集地存储数据，因此更缓存友好。对于涉及整数键的基准测试，我选择预留两个整数值作为这些哨兵（而不是手动将每个键与额外的标志配对），以便该表可以利用这个特性。然而，当这样配置时，这个表在技术上不能容纳其他表可以容纳的完整键范围。

这个表的近似内存开销只是每个桶的键值对填充和每个空桶的键值对大小。

请注意，_OA 后缀作为区分这个表和 M*LIB 的类似命名 DICT 的表的手段，是一个出于与早期版本库的 API 向后兼容性而存在的误称，其中 DICT 使用分离链表。现在，DICT 和 DICT_OA 都是开放寻址表。

- hm 和 sh from stb_ds v0.67：

和 ankerl::unordered_dense 一样，它不直接在哈希表桶中存储键值对，而是连续存储在一个单独的数组中。这个表也在字符串键和所有其他数据类型键的实现之间进行了分割。它依赖墓碑进行擦除。

不幸的是，这个表提供很少的灵活性：要自定义哈希函数、比较函数和最大负载因子，我不得不修改库头文件。尽管如此，我决定将这个库包括在基准测试中，因为它非常受欢迎。

在 x86-64 上，这个表的近似内存开销是每个桶 16 个字节，加上键值对填充，除了空桶的键值对大小。

- hmap from STC v5.0 beta 4：

这个表是一个使用线性探测的开放寻址表。然而，它存储每个键的哈希码的 7 位片段在单独的数组中，以限制直接键比较。这个表的一个不寻常特点是，它不依赖墓碑，而是在给定桶擦除时将随后的键值对，其探测序列包括该桶，向后移动以填补空白。这种技术通常由 Robin Hood 表使用，而不是传统的线性探测表。

这个表的近似内存开销是每个桶一个字节，加上键值对填充，除了空桶的键值对大小。

- uthash v2.3.0：

这是基准测试中包括的最古老和可能最受欢迎的 C 哈希表。像 std::unordered_map 一样，它是基于节点的分离链表表。与其他表相比，它提供的功能是基础的，用户必须自己编写大部分脚手架。它也是这些基准测试中唯一的侵入性表。

在 x86-64 上，这个表的近似内存开销是每个桶 16 个字节和 56 个字节，加上 malloc 头和填充（假设用户单独分配键值对）和键值对填充，每个键值对。

uthash 要求与每个键值对嵌入的 56 字节结构（代码注释省略）：

```c
typedef struct UT_hash_handle {
 struct UT_hash_table *tbl;
 void *prev;
 void *next;
 struct UT_hash_handle *hh_prev;
 struct UT_hash_handle *hh_next;
 const void *key;
 unsigned keylen;
 unsigned hashv;
} UT_hash_handle;
```

- Verstable v2.1.0：

像 ska::bytell_hash_map 一样，这个表是开放寻址和分离链表的混合体，存储从一个桶溢出的键值对在桶数组的其他空桶中。然而，它不是使用 7 位索引到“跳转距离”数组来链式连接键值对，而是使用表示二次位移的 11 位整数。它还存储每个键的哈希码的4位片段以限制键比较。因此，它使用每个桶两字节的元数据，而不是 ska::bytell_hash_map 使用的一个字节。元数据存储在单独的数组中，而不是与桶组交错。

这个表的近似内存开销是每个桶两字节，加上键值对填充，除了空桶的键值对大小。

当然，接下来是文章的继续翻译：

## 结果

由于结果图中的水平尺度是线性的，不是对数的，我针对三个不同的总键值计数运行了基准测试。一般来说，键值计数越低，表在缓存中越热。以下是结果：

- 0 到 200,000 个键
- 0 到 2,000,000 个键
- 0 到 20,000,000 个键

由于我每个键值计数运行了 14 次基准测试，图中显示的每个数据点代表了10次记录的平均值（我排除了两个最高和两个最低的记录，以限制异常值和任何背景处理的影响）。

图表是交互式的。将鼠标悬停在表的标签上以突出显示相关的图表，单击它以切换图表的可见性。图表自动缩放到可见的图表。

下面显示的是 0 到 20,000,000 个键的图表。点击此处跳转到总结这些图表中显示的数据的热图。

- 32位整数键，32位值：插入N个不存在的键所需的总时间

- 64位整数键，448位值：插入N个不存在的键所需的总时间

- 16字符C字符串键，64位值：插入N个不存在的键所需的总时间

- 32位整数键，32位值：在表中有N个键时，删除1,000个现有键所需的时间

- 64位整数键，448位值：在表中有N个键时，删除1,000个现有键所需的时间

- 16字符C字符串键，64位值：在表中有N个键时，删除1,000个现有键所需的时间

- 32位整数键，32位值：在表中有N个键时，替换1,000个现有键所需的时间

- 64位整数键，448位值：在表中有N个键时，替换1,000个现有键所需的时间

- 16字符C字符串键，64位值：在表中有N个键时，替换1,000个现有键所需的时间

- 32位整数键，32位值：在表中有N个键时，删除1,000个不存在的键所需的时间

- 64位整数键，448位值：在表中有N个键时，删除1,000个不存在的键所需的时间

- 16字符C字符串键，64位值：在表中有N个键时，删除1,000个不存在的键所需的时间

- 32位整数键，32位值：在表中有N个键时，查找1,000个现有键所需的时间

- 64位整数键，448位值：在表中有N个键时，查找1,000个现有键所需的时间

- 16字符C字符串键，64位值：在表中有N个键时，查找1,000个现有键所需的时间

- 32位整数键，32位值：在表中有N个键时，查找1,000个不存在的键所需的时间

- 64位整数键，448位值：在表中有N个键时，查找1,000个不存在的键所需的时间

- 16字符C字符串键，64位值：在表中有N个键时，查找1,000个不存在的键所需的时间

- 32位整数键，32位值：在表中有N个键时，遍历5,000个键所需的时间

- 64位整数键，448位值：在表中有N个键时，遍历5,000个键所需的时间

- 16字符C字符串键，64位值：在表中有N个键时，遍历5,000个键所需的时间

## 测试结果一览表

相对于基准中最快的表所花费的总时间（越低/越轻越好）

![Total time taken relative to the fastest table in the benchmark (lower/lighter is better)](./images/benchmark-result-table.png)
